{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e57699d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Tool' from 'langchain_core.agents' (c:\\workspace\\uv_work\\.venv\\Lib\\site-packages\\langchain_core\\agents.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01moperator\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TypedDict, Annotated, List, Union\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AgentAction, AgentFinish, Tool\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessages\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseMessage\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PromptTemplate\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Tool' from 'langchain_core.agents' (c:\\workspace\\uv_work\\.venv\\Lib\\site-packages\\langchain_core\\agents.py)"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "from typing import TypedDict, Annotated, List, Union\n",
    "from langchain_core.agents import AgentAction, AgentFinish, Tool\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt.tool_executor import ToolExecutor\n",
    "from langchain import hub\n",
    "\n",
    "# 기존 상태 클래스 정의\n",
    "class AgentState(TypedDict):\n",
    "    query: str\n",
    "    context: Annotated[List[str], operator.add]\n",
    "    intermediate_steps: Annotated[List[Union[AgentAction, AgentFinish]], operator.add]\n",
    "    answer: str\n",
    "\n",
    "# 1. 환경 설정 및 데이터 로딩 (기존 코드와 동일)\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=200)\n",
    "loader = Docx2txtLoader('./tax.docx')\n",
    "temp = loader.load_and_split(text_splitter=text_splitter)\n",
    "document_list = temp[0:80]\n",
    "\n",
    "embedding = OpenAIEmbeddings(model='text-embedding-3-large')\n",
    "vector_store = Chroma(\n",
    "    collection_name='chroma-tax',\n",
    "    embedding_function=embedding,\n",
    "    persist_directory='./chroma-tax'\n",
    ")\n",
    "retriever = vector_store.as_retriever(search_kwargs={'k': 3})\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "# 2. Tool 정의\n",
    "# 기존 함수들을 LangChain Tool로 감싸서 'tools' 노드에서 실행 가능하도록 만듭니다.\n",
    "# Tool은 특정 작업을 수행하는 데 사용되는 함수나 클래스입니다.\n",
    "\n",
    "def retrieve_tool(query: str) -> List[str]:\n",
    "    \"\"\"사용자의 질문에 기반하여 벡터 스토어에서 관련 문서를 검색합니다.\"\"\"\n",
    "    docs = retriever.invoke(query)\n",
    "    return [doc.page_content for doc in docs]\n",
    "\n",
    "def rewrite_tool(query: str) -> str:\n",
    "    \"\"\"사용자의 질문을 사전에 고려하여 변경합니다.\"\"\"\n",
    "    dictionary = \"사람과 관련된 표현 -> 거주자\"\n",
    "    rewrite_prompt = PromptTemplate.from_template(\n",
    "        f\"\"\"사용자의 질문을 보고, 우리 사전을 참고해서 사용자의 질문을 변경해 주세요.\n",
    "        사전: {dictionary}\n",
    "        질문: {{query}}\n",
    "        \"\"\"\n",
    "    )\n",
    "    rewrite_chain = rewrite_prompt | llm | StrOutputParser()\n",
    "    response = rewrite_chain.invoke({'query': query})\n",
    "    return response\n",
    "\n",
    "# LangChain Tools 리스트\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"retrieve_documents\",\n",
    "        func=retrieve_tool,\n",
    "        description=\"질문에 대한 답변을 생성하기 위해 관련 문서를 검색합니다.\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"rewrite_query\",\n",
    "        func=rewrite_tool,\n",
    "        description=\"질문이 검색에 부적합할 때, 사전을 참고하여 질문을 재작성합니다.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "tool_executor = ToolExecutor(tools)\n",
    "\n",
    "# 3. Agent 노드 정의\n",
    "# Agent는 LLM을 사용하여 어떤 Tool을 호출할지 결정하고, 최종 답변을 생성합니다.\n",
    "\n",
    "agent_prompt = hub.pull(\"hwchase17/react\")\n",
    "agent_prompt = agent_prompt.partial(tools=\", \".join([tool.name for tool in tools]), tool_names=\", \".join([tool.name for tool in tools]))\n",
    "\n",
    "agent_chain = agent_prompt | llm | StrOutputParser()\n",
    "\n",
    "def run_agent(state: AgentState) -> AgentState:\n",
    "    agent_response = agent_chain.invoke(state)\n",
    "    return {\"intermediate_steps\": [AgentAction(tool='tool_name_placeholder', tool_input=agent_response, log=agent_response)]}\n",
    "\n",
    "# 4. Graph 구성\n",
    "# AgentState를 사용하여 상태를 관리하고, 'agent'와 'tools' 노드를 연결합니다.\n",
    "\n",
    "builder = StateGraph(AgentState)\n",
    "builder.add_node(\"agent\", run_agent)\n",
    "builder.add_node(\"tools\", tool_executor)\n",
    "\n",
    "builder.add_edge(START, \"agent\")\n",
    "builder.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "def route_to_tools(state: AgentState):\n",
    "    # Agent의 응답을 기반으로 다음 노드를 결정하는 로직\n",
    "    # 여기서는 Agent의 응답을 파싱하여 Tool 호출 여부를 결정합니다.\n",
    "    # 이 부분은 LangGraph의 Agentic Loop 패턴을 따릅니다.\n",
    "    # Agent가 Tool을 호출하도록 응답하면 'tools'로, 아니면 'end'로 이동합니다.\n",
    "    if \"FINAL ANSWER\" in state['intermediate_steps'][-1].log:\n",
    "        return END\n",
    "    return \"tools\"\n",
    "\n",
    "builder.add_conditional_edges(\"agent\", route_to_tools)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "# 5. 실행\n",
    "# 이제 Agent 노드를 시작으로 그래프를 실행합니다.\n",
    "initial_state = {\"query\": \"연봉 5천만원 직장인의 소득세는?\"}\n",
    "response = graph.invoke(initial_state)\n",
    "\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8194ed2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uv-work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
